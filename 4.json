{
   "author": "Sylvain Duranton",
   "body": "\nPermitam-me compartilhar um paradoxo.\nNos últimos dez anos,\nmuitas empresas vêm tentando\nse tornar menos burocráticas,\nter menos procedimentos\ne regras principais,\nmais autonomia para que\nsuas equipes locais sejam mais ágeis.\nAgora estão pressionando\na inteligência artificial, IA,\nsem saber que essa tecnologia legal\npode torná-las mais\nburocráticas do que nunca.\nPor quê?\nPorque a IA funciona como as burocracias.\n\n\nA essência da burocracia\né favorecer regras e procedimentos\nmais que o julgamento humano.\nA IA decide apenas com base em regras,\nmuitas delas deduzidas\na partir de dados anteriores,\nmas apenas em regras.\nSe o julgamento humano\nnão for mantido nesse processo,\na IA trará uma forma aterrorizante\nde nova burocracia,\nque chamo de \"algocracia\",\nna qual a IA tomará decisões\ncada vez mais críticas segundo as regras\nfora de qualquer controle humano.\nExiste um risco real?\nSim.\n\n\nLidero uma equipe\nde 800 especialistas em IA.\nImplementamos mais de 100\nsoluções de IA personalizadas\npara grandes empresas em todo o mundo.\nVejo muitos executivos de empresas\nse comportando como burocratas do passado.\nEles querem tirar pessoas\ndispendiosas e antiquadas do processo\ne confiar apenas na IA\npara tomar decisões.\nChamo isso de \"mentalidade sem pessoas\".\nPor que é tão tentador?\nPorque o outro caminho,\n\"Pessoas mais IA\", é longo,\ndispendioso e difícil.\nEquipes de negócios, de tecnologia\ne de ciência de dados\nprecisam repetir um processo por meses\npara criar exatamente um modo como pessoas\ne IA possam trabalhar melhor juntas.\nLongo, dispendioso e difícil.\nMas a recompensa é enorme.\n\n\nUma pesquisa recente do BCG e do MIT\nmostra que 18% das empresas do mundo\nsão pioneiras em IA,\nganhando dinheiro com ela.\nEssas empresas concentram\n80% de suas iniciativas de IA\nem eficácia e crescimento,\ntomando melhores decisões\nsem substituir pessoas por IA\npara economizar custos.\n\n\nPor que é importante\nmanter as pessoas nesse processo?\nSimplesmente porque, sozinha,\na IA pode fazer coisas muito idiotas.\nÀs vezes, sem consequências,\ncomo nesta mensagem:\n\"Prezada Amazon,\ncomprei um assento sanitário,\npor necessidade, não por vontade.\nNão os coleciono, nem sou viciado\nem assentos sanitários.\nNão importa quantos e-mails tentadores\nvocê me envie, não vou pensar:\n'Ah, tudo bem, vou me presentear\ncom mais um assento'\".\n\n\n\n\n\n\nÀs vezes, com mais consequências,\ncomo nesta outra mensagem:\n\"Passei pela mesma situação\ncom a urna para cinzas de minha mãe\".\n\n\n\n\n\n\n\"Por meses após a morte dela,\nrecebi mensagens da Amazon\ndizendo: 'Se você gostou...'\"\n\n\n\n\n\n\nÀs vezes, com consequências piores.\nVamos considerar que a IA rejeite\na inscrição de um aluno para a faculdade.\nPor quê?\nPorque ela \"aprendeu\",\npor dados anteriores,\ncaracterísticas de alunos\nque serão aprovados e reprovados.\nAlguns são óbvios,\ncomo notas do vestibular.\nMas se, no passado, todos os alunos\nde um determinado local foram reprovados,\né muito provável\nque a IA torne isso uma regra\ne rejeite todos os alunos desse local,\nsem dar a ninguém a chance de provar\nque a regra está errada.\n\n\nNinguém pode verificar todas as regras,\nporque a IA avançada\nestá aprendendo constantemente.\nSe as pessoas forem deixadas de fora,\nvem o pesadelo \"algocrático\".\nQuem é responsável por rejeitar o aluno?\nNinguém, a IA rejeitou.\nÉ justo? Sim.\nO mesmo conjunto de regras objetivas\nfoi aplicado a todos.\nConseguiríamos reconsiderar\nesse garoto genial do local errado?\nNão, os algoritmos não mudam de ideia.\n\n\nTemos uma escolha aqui:\ncontinuar com a algocracia\nou decidir por \"Pessoas mais IA\".\nPara isso,\nprecisamos parar de pensar\nprimeiro na tecnologia\ne começar a aplicar a fórmula secreta.\nPara implantar \"Pessoas mais IA\",\n10% do esforço\né para codificar algoritmos;\n20% para criar tecnologia\nem torno dos algoritmos,\ncoletar dados, criar interface do usuário,\nintegrar-se a sistemas legados;\nmas 70%, a maior parte do esforço,\nconsiste em combinar IA\ncom pessoas e processos\npara maximizar resultados reais.\n\n\nA IA fracassa ao reduzir os 70%.\nO preço disso pode ser pequeno,\ndesperdiçando muitos milhões\nde dólares em tecnologia inútil.\nAlguém se importa?\nOu tragédias reais:\n346 vítimas\ndos acidentes recentes\nde 2 aeronaves B-737,\nem que os pilotos não conseguiram\ninteragir adequadamente\ncom um sistema de comando computadorizado.\n\n\nPara 70% de sucesso,\no primeiro passo é garantir\nque os algoritmos sejam codificados\npor cientistas de dados\ne especialistas no assunto juntos.\nConsiderem, por exemplo,\na assistência médica.\nUma de nossas equipes\ntrabalhou em um novo medicamento\nque apresentava um pequeno problema.\nAo tomar a primeira dose,\nalguns pacientes, muito poucos,\ntêm ataques cardíacos.\nAssim, todos os pacientes,\nquando tomam a primeira dose,\nprecisam passar um dia no hospital,\npara monitoramento, apenas por precaução.\nNosso objetivo era identificar pacientes\ncom risco zero de ataques cardíacos,\nque não precisariam\npassar o dia no hospital.\nUtilizamos a IA para analisar\ndados de ensaios clínicos,\npara correlacionar eletrocardiograma,\ncomposição sanguínea, biomarcadores,\ncom o risco de ataque cardíaco.\nEm um mês,\nnosso modelo conseguiu sinalizar\n62% de pacientes com risco zero.\nEles não precisariam\npassar o dia no hospital.\nVocês ficariam à vontade em casa\npara sua primeira dose\nse o algoritmo dissesse isso?\n\n\n\n\n\n\nOs médicos não ficaram.\nE se tivéssemos falsos negativos,\nou seja, pessoas que a IA\npermite ficar em casa e que morrem?\n\n\n\n\n\n\nNossos 70% começavam por aí.\nTrabalhamos com uma equipe de médicos\npara verificar a lógica médica\nde cada variável de nosso modelo.\nPor exemplo, usamos a concentração\nde uma enzima hepática\ncomo um indicador,\npara o qual a lógica médica não era óbvia.\nO sinal estatístico era bastante forte.\nMas e se fosse um viés em nossa amostra?\nEsse indicador foi retirado do modelo.\nTambém retiramos indicadores\npara os quais os especialistas disseram\nque não podem ser rigorosamente medidos\npor médicos na vida real.\nApós quatro meses,\ntínhamos um modelo e um protocolo médico.\nAmbos foram aprovados\npor autoridades médicas dos EUA\nna primavera passada,\nresultando em muito menos estresse\npara metade dos pacientes,\nmelhor qualidade de vida\ne um aumento esperado nas vendas\nacima de 100 milhões\npara esse medicamento.\n\n\nSetenta por cento combinando IA\ncom equipe e processos\ntambém significa construir\ninterfaces poderosas\npara pessoas e IA resolverem juntas\nos problemas mais difíceis.\nUma vez, fomos desafiados\npor uma loja de roupas.\n\"Temos os melhores compradores do mundo.\nVocê poderia criar um mecanismo de IA\nque os superasse em prever vendas?\nEm informar quantas camisas masculinas GG\nverde-claras de alta qualidade\nprecisamos comprar para o ano seguinte?\nEm prever melhor o que venderá ou não\ndo que nossos estilistas?\"\nNossa equipe treinou um modelo\nem poucas semanas,\ncom dados de vendas anteriores,\ne a competição foi organizada\ncom compradores humanos.\nO resultado?\nA IA vence, reduzindo\nerros de previsão em 25%.\nCampeões sem pessoas poderiam ter\ntentado implementar esse modelo inicial\ne criar uma briga com todos\nos compradores humanos.\nDivirtam-se.\nMas sabíamos\nda percepção de compradores humanos\nsobre tendências da moda,\nque não poderia ser encontrada\nem dados anteriores.\n\n\nNossos 70% começavam por aí.\nFizemos um segundo teste,\nem que compradores humanos\nreviam quantidades,\nsugeridas pela IA,\ne poderiam corrigi-las se necessário.\nO resultado?\nPessoas usando IA...\nperde.\nSetenta e cinco por cento\ndas correções feitas por uma pessoa\nreduziram a precisão.\n\n\nEra hora de se livrar\nde compradores humanos?\nNão.\nEstava na hora de recriar um modelo\nem que as pessoas não tentassem\nadivinhar quando a IA estava errada,\nmas em que a IA recebesse\ninformações reais de compradores humanos.\nReconstruímos totalmente o modelo\ne nos afastamos\nde nossa interface inicial,\nque era mais ou menos:\n\"Ei, pessoas! É isso que prevejo,\ncorrijam o que quiserem\",\ne passamos para uma interface\nmuito mais rica, mais como:\n\"Ei, pessoas!\nNão conheço as tendências do próximo ano.\nPoderiam compartilhar comigo\nsuas apostas mais criativas?\"\n\"Ei, pessoas!\nPoderiam me ajudar a quantificar\nesses poucos grandes itens?\nNão consegui encontrar um bom\ncomparativo no passado para eles.\"\nO resultado?\n\"Pessoas mais IA\" vence,\nreduzindo erros de previsão em 50%.\nLevou um ano para finalizar a ferramenta.\nLongo, dispendioso e difícil.\nMas os lucros e os benefícios\nexcederam 100 milhões\nde economia por ano para essa loja.\n\n\nSetenta por cento\nem assuntos muito confidenciais\ntambém significam que as pessoas\nprecisam decidir o que é certo ou errado\ne definir regras para o que a IA\npode fazer ou não,\ncomo estabelecer limites de preços\npara impedir mecanismos de precificação\nde cobrar preços absurdamente altos\npara clientes sem instrução\nque os aceitariam.\nSomente as pessoas\nsabem definir esses limites.\nA IA não consegue encontrá-los\nem dados anteriores.\n\n\nAlgumas situações se encontram\nna região intermediária.\nTrabalhamos com um plano de saúde\nque desenvolveu um mecanismo de IA\npara identificar, entre seus clientes,\npessoas que estão prestes\na serem internadas\npara lhes vender serviços diferenciados.\nO problema é que prováveis clientes\nforam contatados pela equipe comercial\nembora ainda não soubessem\nque seriam internados em breve.\nVocê é o CEO dessa empresa.\nVocê interromperia esse programa?\nNão é uma pergunta fácil.\n\n\nPara resolver essa questão,\nalgumas empresas criam equipes,\ndefinem regras e padrões éticos\npara ajudar equipes de tecnologia\ne negócios a estabelecerem limites\nentre personalização e manipulação,\npersonalização de ofertas e discriminação,\nsegmentação e invasão.\n\n\nEstou convencido\nde que, em todas as empresas,\nutilizar a IA onde realmente importa\noferece um enorme retorno financeiro.\nLíderes de negócios precisam ser ousados\ne selecionar alguns assuntos\ne, para cada um deles, mobilizar 10, 20,\n30 pessoas de suas melhores equipes,\nde tecnologia, IA,\nciência de dados e ética,\ne passar pelo ciclo completo\nde 10, 20, 70%\nde \"Pessoas mais IA\",\nse quiserem colocar a IA efetivamente\nem suas equipes e processos.\nNão há outra maneira.\n\n\nCidadãos de economias desenvolvidas\njá temem a algocracia.\nSete mil foram entrevistados\nem uma pesquisa recente.\nMais de 75% expressaram preocupações reais\nsobre o impacto da IA\nna força de trabalho, na privacidade\ne no risco de uma sociedade desumanizada.\nPressionar a algocracia cria um risco real\nde reação grave contra a IA\nnas empresas ou na sociedade em geral.\n\"Pessoas mais IA\" é nossa única opção\npara trazer os benefícios da IA\npara o mundo real.\nNo final, as organizações vencedoras\ninvestirão em conhecimento humano,\nnão apenas em IA e dados.\nRecrutando, treinando,\nrecompensando especialistas humanos.\nDizem que os dados são o novo petróleo,\nmas, acreditem, o conhecimento\nhumano fará a diferença,\nporque é a única torre disponível\npara bombear o petróleo oculto nos dados.\n\n\nObrigado.\n\n\n\n\n\n",
   "title": "Como as pessoas e a inteligência artificial podem trabalhar juntas para criar melhores negócios",
   "type": "video",
   "url": "https://www.ted.com/talks/sylvain_duranton_how_humans_and_ai_can_work_together_to_create_better_businesses/transcript?language=pt-br"
}